---
title: '1223'
author: "David Deniziuk"
date: "4/3/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Import Libraries And Data

```{r, warning=F, message=F}
library(readr)
library(tidyverse)
library(dplyr)
library(tidyr)
library(glmnet)
library(MASS)
library(ggplot2)
```

```{r}
MMA <- read_csv("/Users/david/Code/1223/mma_new.csv" ) 
```


## Data Manipulation and Exploration

I begin to clean the raw data.  I filter for rows in which significant strikes are actually landed and then select the desired features. Lastly, I create the response variable, rwin.
```{r, warning = F, message = F}

MMA_filtered <- as.data.frame(MMA) %>%
  filter(winby == "KO/TKO") %>%
  filter(`B__Round1_Strikes_Significant Strikes_Landed` != "NA") %>%
  filter(`B__Round2_Strikes_Significant Strikes_Landed` != "NA") %>%
  filter(`R__Round1_Strikes_Significant Strikes_Landed` != "NA") %>%
  filter(`R__Round2_Strikes_Significant Strikes_Landed` != "NA") %>%
  dplyr::select(-c('B_ID','R_ID','B_Name','R_Name','Date','Event_ID','Max_round','B__Round3_Strikes_Body Significant Strikes_Landed','B__Round3_Strikes_Clinch Significant Strikes_Landed','B__Round3_Strikes_Ground Significant Strikes_Landed','B__Round3_Strikes_Head Significant Strikes_Landed','B__Round3_Strikes_Legs Significant Strikes_Landed','B__Round3_Strikes_Significant Strikes_Landed','R__Round3_Strikes_Body Significant Strikes_Landed','R__Round3_Strikes_Clinch Significant Strikes_Landed','R__Round3_Strikes_Ground Significant Strikes_Landed','R__Round3_Strikes_Head Significant Strikes_Landed','R__Round3_Strikes_Legs Significant Strikes_Landed','R__Round3_Strikes_Significant Strikes_Landed','winby'
            ))%>%
  rename(B_1_body = `B__Round1_Strikes_Body Significant Strikes_Landed`,
         B_1_clinch = `B__Round1_Strikes_Clinch Significant Strikes_Landed`,
         B_1_ground = `B__Round1_Strikes_Ground Significant Strikes_Landed`,
         B_1_head = `B__Round1_Strikes_Head Significant Strikes_Landed`,
         B_1_legs = `B__Round1_Strikes_Legs Significant Strikes_Landed`,
         B_1_total = `B__Round1_Strikes_Significant Strikes_Landed`,
         B_2_body = `B__Round2_Strikes_Body Significant Strikes_Landed`,
         B_2_clinch = `B__Round2_Strikes_Clinch Significant Strikes_Landed`,
         B_2_ground = `B__Round2_Strikes_Ground Significant Strikes_Landed`,
         B_2_head = `B__Round2_Strikes_Head Significant Strikes_Landed`,
         B_2_legs = `B__Round2_Strikes_Legs Significant Strikes_Landed`,
         B_2_total = `B__Round2_Strikes_Significant Strikes_Landed`,
         R_1_body = `R__Round1_Strikes_Body Significant Strikes_Landed`,
         R_1_clinch = `R__Round1_Strikes_Clinch Significant Strikes_Landed`,
         R_1_ground = `R__Round1_Strikes_Ground Significant Strikes_Landed`,
         R_1_head = `R__Round1_Strikes_Head Significant Strikes_Landed`,
         R_1_legs = `R__Round1_Strikes_Legs Significant Strikes_Landed`,
         R_1_total = `R__Round1_Strikes_Significant Strikes_Landed`,
         R_2_body = `R__Round2_Strikes_Body Significant Strikes_Landed`,
         R_2_clinch = `R__Round2_Strikes_Clinch Significant Strikes_Landed`,
         R_2_ground = `R__Round2_Strikes_Ground Significant Strikes_Landed`,
         R_2_head = `R__Round2_Strikes_Head Significant Strikes_Landed`,
         R_2_legs = `R__Round2_Strikes_Legs Significant Strikes_Landed`,
         R_2_total = `R__Round2_Strikes_Significant Strikes_Landed`) %>%
  mutate(pR_1_body = R_1_body/(R_1_body+B_1_body),
         pR_1_clinch = R_1_clinch/(R_1_clinch+B_1_clinch),
         pR_1_ground = R_1_ground/(R_1_ground+B_1_ground),
         pR_1_head = R_1_head/(R_1_head+B_1_head),
         pR_1_legs = R_1_legs/(R_1_legs+B_1_legs),
         pR_1_total = R_1_total/(R_1_total+B_1_total),
         
         pR_12_body = (R_1_body+R_2_body)/(R_1_body+R_2_body+B_1_body+B_2_body),
         pR_12_clinch = (R_1_clinch+R_2_clinch)/(R_1_clinch+R_2_clinch+B_1_clinch+B_2_clinch),
         pR_12_ground = (R_1_ground+R_2_ground)/(R_1_ground+R_2_ground+B_1_ground+B_2_ground),
         pR_12_head = (R_1_head+R_2_head)/(R_1_head+R_2_head+B_1_head+B_2_head),
         pR_12_legs = (R_1_legs+R_2_legs)/(R_1_legs+R_2_legs+B_1_legs+B_2_legs),
         pR_12_total = (R_1_total+R_2_total)/(R_1_total+R_2_total+B_1_total+B_2_total)) %>%
  mutate(rwin = ifelse((winner == 'red'),1,0)) %>%
  dplyr::select(-"winner")%>%
  filter(Last_round != 1) 
```

Here we filter to only fights ending in rounds two or three.  This eliminates a) fights which last more than three rounds (title bouts), and b) fights which end in the first round.  We do not want to look at first round ending fights, because those do not investigate the hypothesis of "chronic weakening" between rounds.  
```{r}
MMA_KO2 <- MMA_filtered %>% filter(Last_round == 2)
MMA_KO3 <- MMA_filtered %>% filter(Last_round == 3)
head(MMA_KO2)
head(MMA_KO3)
```

remove bad rows
```{r}
MMA_KO2 <- na.omit(MMA_KO2)
MMA_KO3 <- na.omit(MMA_KO3) 
```

temp dataframe for the piecharts of response variable
```{r}
KO2_oneprop <- sum(MMA_KO2$rwin)/nrow(MMA_KO2)
KO2_zeroprop <- 1-KO2_oneprop
KO3_oneprop <- sum(MMA_KO3$rwin)/nrow(MMA_KO3)
KO3_zeroprop <- 1-KO3_oneprop

piechart <- tibble(value_02 = c(KO2_oneprop,KO2_zeroprop),
                       value_03 = c(KO3_oneprop,KO3_zeroprop),
                       rwin = as.factor(c(1,0)))
```

piechart for round two KO
```{r}
ggplot(piechart, aes(x="", y=value_02, fill=rwin))+
 geom_bar(width=1,stat="identity")+
  coord_polar("y",start = 0)+
  theme_void()+
  labs(title="Round 2 KO/TKO")+
  theme(plot.title = element_text(size=36))
```

piechart for round three KO
```{r}
ggplot(piechart, aes(x="", y=value_03, fill=rwin))+
 geom_bar(width=1,stat="identity")+
  coord_polar("y",start = 0)+
  theme_void()+
  labs(title="Round 3 KO/TKO")+
    theme(plot.title = element_text(size=36))
```

basic standard deviation calculations for round two KOs
```{r}
sd(MMA_KO2$pR_1_body)
sd(MMA_KO2$pR_1_clinch)
sd(MMA_KO2$pR_1_ground)
sd(MMA_KO2$pR_1_head)
sd(MMA_KO2$pR_1_legs)
```

basic standard deviation calculations for round three KOs
```{r}
sd(MMA_KO3$pR_12_body)
sd(MMA_KO3$pR_12_clinch)
sd(MMA_KO3$pR_12_ground)
sd(MMA_KO3$pR_12_head)
sd(MMA_KO3$pR_12_legs)
```





## Modeling







### Full Models:


simply building the models here.  validation done later in code

full multiple binary logistic regression for round two KOs
```{r,message = F}
attach(MMA_KO2)
KO2.fit <- glm(rwin ~ pR_1_body+pR_1_clinch+pR_1_ground+pR_1_head+pR_1_legs, data = MMA_KO2, family = binomial)
KO2.probs <- predict(KO2.fit,type = "response")
KO2.pred <- ifelse(KO2.probs > 0.5, "1", "0")
table(KO2.pred,rwin)
summary(KO2.fit)$coefficients
detach(MMA_KO2)
```
accuracy = (33 + 33)/(33+18+16+33) = 66/100 = 66.0%


full multiple binary logistic regression for round three KOs
```{r,message = F}
attach(MMA_KO3)
KO3.fit <- glm(rwin ~ pR_12_body+pR_12_clinch+pR_12_ground+pR_12_head+pR_12_legs, data = MMA_KO3, family = binomial)
KO3.probs <- predict(KO3.fit,type = "response")
KO3.pred <- ifelse(KO3.probs > 0.5, "1", "0")
table(KO3.pred,rwin)
summary(KO3.fit)
detach(MMA_KO3)
```
accuracy: (20+19)/(20+12+10+19) = 39/61 = 63.9%



### Choosing Models Via Backward Elimination With AIC As Criterion



round two KOs
```{r}
step.KO2.fit <- KO2.fit %>% stepAIC(trace = T)
summary(step.KO2.fit)
```

For round 2 knockouts, the model with one predictor, proportion of round one significant head strikes, is chosen as the sole predictor variable when AIC is the model selection criterion used.  

round three KOs
```{r}
step.KO3.fit <- KO3.fit %>% stepAIC(trace = T)
summary(step.KO3.fit)
```
For round 3 knockouts, the model with one predictor, proportion of round one significant body strikes, is chosen as the sole predictor variable when AIC is the model selection criterion used. 



### Model Backward Elimination AIC Chosen Variables



round two KOs
```{r,message=F}
attach(MMA_KO2)
KO2.probs <- predict(step.KO2.fit,type = "response")
KO2.pred <- ifelse(KO2.probs > 0.5, "1", "0")
table(KO2.pred,rwin)
detach(MMA_KO2)
```
Accuracy: (31+30)/(30+20+19+31) = 61/100 = 61.0%


round three KOs
```{r,message=F}
attach(MMA_KO3)
KO3.probs <- predict(step.KO3.fit,type = "response")
KO3.pred <- ifelse(KO3.probs > 0.5, "1", "0")
table(KO3.pred, rwin)
detach(MMA_KO3)
```
accuracy: (19+22)/(19+9+11+22) = 41/61 = 67.2%  (more accurate than full model, surprisingly)



### Train/Test Full Models



validation set full model
round two KOs
```{r, message=F}
set.seed(1)
train_index_MMA_KO2 <- sample(nrow(MMA_KO2), nrow(MMA_KO2)*0.75)
train_MMA_KO2 <- MMA_KO2[train_index_MMA_KO2,]
test_MMA_KO2 <- MMA_KO2[-train_index_MMA_KO2,]


attach(MMA_KO2)
KO2.fit <- glm(rwin ~ pR_1_body+pR_1_clinch+pR_1_ground+pR_1_head+pR_1_legs, data = train_MMA_KO2, family = binomial)
KO2.probs <- predict(KO2.fit, newdata=test_MMA_KO2, type = "response")
KO2.pred <- ifelse(KO2.probs > 0.5, "1", "0")
table(KO2.pred,test_MMA_KO2$rwin)
detach(MMA_KO2)
KO2.probs
```
accuracy: (10+3)/(3+2+10+10) = 13/25 = 52%


validation set full model
round three KOs
```{r, message=F}
set.seed(1)
train_index_MMA_KO3 <- sample(nrow(MMA_KO3), nrow(MMA_KO3)*0.75)
train_MMA_KO3 <- MMA_KO3[train_index_MMA_KO3,]
test_MMA_KO3 <- MMA_KO3[-train_index_MMA_KO3,]


attach(MMA_KO3)
KO3.fit <- glm(rwin ~ pR_12_body+pR_12_clinch+pR_12_ground+pR_12_head+pR_12_legs, data = train_MMA_KO3, family = binomial)
KO3.probs <- predict(KO3.fit, newdata=test_MMA_KO3, type = "response")
KO3.pred <- ifelse(KO3.probs > 0.5, "1", "0")
table(KO3.pred,test_MMA_KO3$rwin)
detach(MMA_KO3)
```
accuracy: (4+3)/(3+3+6+4) = 9/16 = 43.8%  *Worse than random guessing

From these two results, we can see that these models do not have great amounts of predictive accuracy.



### Train/Test Backward Elimination AIC Models



Now I will re-run these reduced models with a randomized train and test set to see if they truly generalize well.  Stepwise regression with AIC as the model selection criterion should choose models that have lower misclassification rate than that of full models. 

round two KOs
```{r, message=F}
set.seed(1)
train_index_MMA_KO2 <- sample(nrow(MMA_KO2), nrow(MMA_KO2)*0.75)
train_MMA_KO2 <- MMA_KO2[train_index_MMA_KO2,]
test_MMA_KO2 <- MMA_KO2[-train_index_MMA_KO2,]


attach(MMA_KO2)
KO2.fit <- glm(rwin ~ pR_1_head, data = train_MMA_KO2, family = binomial)
KO2.probs <- predict(KO2.fit, newdata=test_MMA_KO2, type = "response")
KO2.pred <- ifelse(KO2.probs > 0.5, "1", "0")
table(KO2.pred,test_MMA_KO2$rwin)
detach(MMA_KO2)
```
accuracy: (7+8)/(7+4+6+8) = 15/25 = 60.0%   better than that of the full model 


round three KOs
```{r, message=F}
set.seed(1)
train_index_MMA_KO3 <- sample(nrow(MMA_KO3), nrow(MMA_KO3)*0.75)
train_MMA_KO3 <- MMA_KO3[train_index_MMA_KO3,]
test_MMA_KO3 <- MMA_KO3[-train_index_MMA_KO3,]


attach(MMA_KO3)
KO3.fit <- glm(rwin ~ pR_12_body, data = train_MMA_KO3, family = binomial)
KO3.probs <- predict(KO3.fit, newdata=test_MMA_KO3, type = "response")
KO3.pred <- ifelse(KO3.probs > 0.5, "1", "0")
table(KO3.pred,test_MMA_KO3$rwin)
detach(MMA_KO3)
```
accuracy: (2+6)/(2+1+7+6) = 8/16 = 50.0%   once again, better than that of the full model 

Although both of the single-predictor models perform better than their full-model counterparts, we still do not have great predictive accuracy.  The sample size is also very small after splitting into train/test sets.



### Plot The AIC Chosen Models



second round KOs
```{r,message=F}
# Create a range of income values (we'll cover a wider range then the dataset)
# The range of values must be saved in a data frame and must have the same column
# name as that given in the original dataset
attach(MMA_KO2)
Round2 <- data.frame(pR_1_head = seq(from = 0, to = 1, by = 0.001))

#Predict the Coast values (as a probability) using the above data
Round2$rwin <- predict(KO2.fit, newdata=Round2, type="response")

# Plot the modeled probability values
ggplot(Round2, aes(x=pR_1_head, y=rwin)) + geom_line()
detach(MMA_KO2)
```

third round KOs
```{r,message=F}
# Create a range of income values (we'll cover a wider range then the dataset)
# The range of values must be saved in a data frame and must have the same column
# name as that given in the original dataset
attach(MMA_KO3)
Round3 <- data.frame(pR_12_body = seq(from = 0, to = 1, by = 0.001))

#Predict the Coast values (as a probability) using the above data
Round3$rwin <- predict(KO3.fit, newdata=Round3, type="response")

# Plot the modeled probability values
ggplot(Round3, aes(x=pR_12_body, y=rwin)) + geom_line()
detach(MMA_KO3)
```



### Plotting Linearity In Predictor Variables



round two
```{r}
KO2.fit <- glm(rwin ~ pR_1_body+pR_1_clinch+pR_1_ground+pR_1_head+pR_1_legs, data = MMA_KO2, family = binomial)
KO2.probs <- predict(KO2.fit,type = "response")

Round_1_head <- MMA_KO2$pR_1_head
MMA_KO2_new <- MMA_KO2 %>%
  mutate(logit2 = log(KO2.probs/(1-KO2.probs))) 
```

```{r}
ggplot(MMA_KO2_new, aes(logit2, Round_1_head))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() 
```

round three
```{r}
attach(MMA_KO3)
KO3.fit <- glm(rwin ~ pR_12_body+pR_12_clinch+pR_12_ground+pR_12_head+pR_12_legs, data = MMA_KO3, family = binomial)
KO3.probs <- predict(KO3.fit,type = "response")

Round_12_body <- MMA_KO3$pR_12_body
MMA_KO3_new <- MMA_KO3 %>%
  mutate(logit3 = log(KO3.probs/(1-KO3.probs))) 
```

```{r}
ggplot(MMA_KO3_new, aes(logit3, pR_12_body))+
  geom_point(size = 0.5, alpha = 0.5) +
  geom_smooth(method = "loess") + 
  theme_bw() 
```











